{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f82b07ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import sqlalchemy\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd \n",
    "import nltk as nlp\n",
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "stopWords = set(stopwords.words('turkish'))\n",
    "from sklearn import preprocessing\n",
    "import jpype\n",
    "from typing import List\n",
    "from jpype import JClass, JString, getDefaultJVMPath, shutdownJVM, startJVM, java\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import pipeline\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased') # BERT tokenizer'ı yükleme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d13a0d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_string = \"DRIVER={SQL Server};SERVER=MIMI\\SNK2000004504;DATABASE=BrandReputation;UID=sa;PWD=170402\"\n",
    "connection = pyodbc.connect(connection_string)\n",
    "\n",
    "connection_string = 'mssql+pyodbc://sa:170402@MIMI\\\\SNK2000004504/BrandReputation?driver=SQL+Server'\n",
    "# Create the engine\n",
    "engine = sqlalchemy.create_engine(connection_string)\n",
    "\n",
    "#catalog = 'Fırın'\n",
    "\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(\"\"\"\n",
    "SELECT Comment\n",
    "FROM dbo.amazonsingledata\n",
    "WHERE Label IS NULL AND Score IS NULL\n",
    "\"\"\")\n",
    "sonuc = cursor.fetchall()\n",
    "\n",
    "# Parametreleri kullanarak pandas ile veri çekme\n",
    "df_train = pd.read_sql_query(\n",
    "    f\"SELECT Comment FROM dbo.amazonsingledata WHERE Label IS NULL AND Score IS NULL\",\n",
    "    engine\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7765de61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>en küçük boy tencerenin kapağı durduk yere dah...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3 ay kullanım sonrası bir kullanıcı deneyimi p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bütün eşyalar çekilmiş ilk temizliği yapılmış ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anker çok yüksek teknolojili çok sağlam ürünle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2 hafta sonra mop yaparken değişik gıcırdama b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Renk olarak sarı lacivert geleceği yazıyordu a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Sağlam ve güzel kullanışlı</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Farklı renkte ürün geldi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Gayet güzel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Ürünün malzemeleri kaliteli olsada kalemtraş k...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Comment\n",
       "0   en küçük boy tencerenin kapağı durduk yere dah...\n",
       "1   3 ay kullanım sonrası bir kullanıcı deneyimi p...\n",
       "2   Bütün eşyalar çekilmiş ilk temizliği yapılmış ...\n",
       "3   Anker çok yüksek teknolojili çok sağlam ürünle...\n",
       "4   2 hafta sonra mop yaparken değişik gıcırdama b...\n",
       "..                                                ...\n",
       "94  Renk olarak sarı lacivert geleceği yazıyordu a...\n",
       "95                         Sağlam ve güzel kullanışlı\n",
       "96                           Farklı renkte ürün geldi\n",
       "97                                        Gayet güzel\n",
       "98  Ürünün malzemeleri kaliteli olsada kalemtraş k...\n",
       "\n",
       "[99 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db5ef756",
   "metadata": {},
   "outputs": [],
   "source": [
    "bounti = pipeline(\"sentiment-analysis\", model=\"akoksal/bounti\", framework=\"pt\")\n",
    "\n",
    "with open(\"C:/Users/sueda/Downloads/turkish_stopwords (1).txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    stop_words_from_file = file.readlines()\n",
    "\n",
    "# Her satırdaki '\\n' karakterlerini kaldır\n",
    "stop_words_from_file = [word.strip() for word in stop_words_from_file]\n",
    "\n",
    "# stop_word_list'e ekleyin\n",
    "stop_word_list = []\n",
    "stop_word_list.extend(stop_words_from_file)\n",
    "\n",
    "\n",
    "max_seq_length = 510\n",
    "\n",
    "def process_text(text):\n",
    "    try:\n",
    "        hashtags = [i[1:] for i in text.split() if i.startswith('#')] # Metindeki hashtag'leri ayıkla\n",
    "        text = re.sub(r'\\b\\w*@\\w*\\b', '', text) # @ içeren kelimeleri kaldır      \n",
    "        text = re.sub(r'\\bhttp\\S+\\b', '', text) # http içeren kelimeleri kaldır\n",
    "        text = text.replace('I','ı')\n",
    "        text = text.replace('İ','i')\n",
    "        text = text.lower()      \n",
    "        # Metindeki alfabetik olmayan karakterleri temizle\n",
    "        if not any (c.isalpha() for c in text):\n",
    "            return text\n",
    "        text = re.sub('\\W+', ' ', str(text)) # Tüm özel karakterleri temizle\n",
    "        text = re.sub(\"[^abcçdefgğhıijklmnoöprsştuüvyz]\",\" \",text)\n",
    "        text = \" \".join([j for j in text.split() if j not in stop_word_list]) # stop word temizle  \n",
    "        text = \" \".join([i for i in text.split() if len(i) > 1])   # Tek harfli kelimeleri temizle  \n",
    "        tokens = tokenizer.tokenize(text)\n",
    "        shortened_tokens = tokens[:max_seq_length]\n",
    "        text = tokenizer.convert_tokens_to_string(shortened_tokens)\n",
    "        return text\n",
    "    except AttributeError:\n",
    "        return \"\"\n",
    "\n",
    "# Emoji DataFrame'ini oku\n",
    "dfemoji = pd.read_excel('C:/Users/sueda/Desktop/emojiSentiment.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d3a9b7f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# DataFrame'i oku\n",
    "df_train[\"lemma\"] =df_train[\"Comment\"].apply(lambda x: process_text(x))\n",
    "\n",
    "for index, row in df_train.iterrows():\n",
    "    post = row[\"Comment\"]\n",
    "    comment = row[\"lemma\"]\n",
    "    if comment.strip() and not any(c.isalpha() for c in comment):\n",
    "        # Comment'in karakter sayısına göre ortalama sentiment score hesapla\n",
    "        max_score = float('-inf')  # En yüksek skoru tutacak değişken\n",
    "        max_label = None  # En yüksek skora karşılık gelen etiket\n",
    "        \n",
    "        for char in comment:\n",
    "            mask = dfemoji[\"Char\"] == char\n",
    "            emoji_row = dfemoji[mask]\n",
    "            if not emoji_row.empty:\n",
    "                emoji_score = emoji_row.iloc[0][\"Sentiment score\"]\n",
    "                if emoji_score > max_score:\n",
    "                    max_score = emoji_score\n",
    "                    max_label = emoji_row.iloc[0][\"Sentiment label\"]\n",
    "        \n",
    "        # Eğer karakter bulunamazsa, skoru ve etiketi 0 ve \"neutral\" olarak ayarla\n",
    "        if max_label is None:\n",
    "            max_score = 0.0\n",
    "            max_label = \"neutral\"\n",
    "        \n",
    "        cursor.execute(\"UPDATE dbo.amazonsingledata SET Label = ? , Score = ? WHERE CAST(Comment AS nvarchar(max)) = CAST(? AS nvarchar(max))\", (max_label, max_score, post))\n",
    "        connection.commit()\n",
    "    else:\n",
    "        result = bounti(comment)\n",
    "        label = result[0][\"label\"] \n",
    "        if label == \"negative\":\n",
    "            score = -1 * round(result[0][\"score\"], 5)\n",
    "        else:\n",
    "            score = round(result[0][\"score\"], 5)\n",
    "        \n",
    "        # Veritabanında güncelleme yap\n",
    "        cursor.execute(\"UPDATE dbo.amazonsingledata SET Label = ? , Score = ? WHERE CAST(Comment AS nvarchar(max)) = CAST(? AS nvarchar(max))\", (label, score, post)) \n",
    "        connection.commit()\n",
    "# Değişiklikleri kaydet\n",
    "connection.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0674d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcd5c38d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hızlı kargo urun iyi bekledigimden koku neredeyse yok'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fa64d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection.commit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
